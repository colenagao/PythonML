{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dxy_wczp6w1l",
        "RvXfomFE61Fj",
        "c2D-2VDWqhVO",
        "fboLHtU5VqLe",
        "4oTZQoQq759g",
        "7ossyEvkzsJj",
        "4LsZjoTI68hr",
        "1rdTNAf87Baa",
        "MegEn0--1e6y",
        "gUWQYu6pI8GC"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**CSE164 Final Project: Semi-supervised Learning**\n",
        "**This project is made to be run in Google Colab**\n",
        "\n",
        ">Model File: https://drive.google.com/file/d/1GQHO3t8iA9F-1Wu1JxTjwY--9_bfdRbc/view?usp=sharing\n",
        "\n",
        "> credit to this tutorial for using tf hub: https://www.tensorflow.org/hub/tutorials/tf2_image_retraining"
      ],
      "metadata": {
        "id": "8OnmzLu96l4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Run\n",
        "=================="
      ],
      "metadata": {
        "id": "jDDI3ZAWNGMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this notebook, import your kaggle.json api file into the content folder of the colab runtime then hit run all. This should take aproximately 10-12 minutes to complete.\n",
        "\n",
        "Please note that running the following notebook automatically creates a kaggle submission. If you also want the full prediction.csv file you can download that directly from the runtime files.\n",
        "\n",
        "On a secondary Note, it might tell you this notebook requires high ram, that is only the case if you run the predictions multiple times because tf is a memory hog. Running the whole thing one time through only requires about 9GB's of RAM"
      ],
      "metadata": {
        "id": "STR7hDSPNLGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network Backbone\n",
        "==================\n",
        "\n"
      ],
      "metadata": {
        "id": "R8WSpAh3CAtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning\n",
        "> Supervised Learning\n",
        ">> Semi-supervised Learning would lead to marginal returns given the size of the pretrained model training time is (45 min/epoch) no noticable prediction score (~75%)\n",
        ">\n",
        "> Data Augmentation Layer + Preprocessing at the top\n",
        ">\n",
        "> Swin-t Transformer: https://tfhub.dev/sayakpaul/swin_base_patch4_window7_224/1\n",
        ">\n",
        "> Dense(200) + Dropout(.2) + Softmax(10)\n",
        ">\n",
        "\n"
      ],
      "metadata": {
        "id": "eF_ZtXJbEYj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Pipeline\n",
        "=================="
      ],
      "metadata": {
        "id": "rcy1diCeEePs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab\n",
        "> Easier to work with + same compute power\n",
        "\n",
        "Import data directly from Kaggle using CLI\n",
        "\n",
        "Preprocess images(Normalize + Augment)\n",
        "> The Swin-t does its own preprocessing it just needs normalized images\n",
        "\n",
        "Batch and shuffle the sets\n",
        "> Tuned to work with the small dataset\n",
        "\n",
        "Use a 20% subset of the given training data as a validation set\n",
        "\n",
        "Early Stopping + Model Checkpoint\n",
        "> Don't waste any training time and reduce overfitting\n",
        ">\n",
        "> Increase the luck for training scores by running multiple times and saving the best score"
      ],
      "metadata": {
        "id": "Ux6yn-2pEeMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix Seed for Reproducible Results\n",
        "=================="
      ],
      "metadata": {
        "id": "dxy_wczp6w1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcCIy5oZoXwW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from functools import partial\n",
        "import copy\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some stuff we'll need...\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "metadata": {
        "id": "zNgnlcmqhkU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "nIIgQRvZoeE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "MFTALPGYfFNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "KBmhhN26fRQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Yp26VxOFfd_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "FBJ1O4d_fov-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data From Kaggle\n",
        "=================="
      ],
      "metadata": {
        "id": "RvXfomFE61Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c ucsc-cse-164-spring-2023-final-project"
      ],
      "metadata": {
        "id": "O1pO-nAlfvP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9a9814-b3de-41c8-ca6b-37c938fa2877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q ucsc-cse-164-spring-2023-final-project.zip -d data"
      ],
      "metadata": {
        "id": "O__MCNb6hE71",
        "outputId": "7877eb0b-3b65-4ebc-b6e1-bbedd4bfd153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open ucsc-cse-164-spring-2023-final-project.zip, ucsc-cse-164-spring-2023-final-project.zip.zip or ucsc-cse-164-spring-2023-final-project.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load datasets\n",
        "=================="
      ],
      "metadata": {
        "id": "TQc9g8lIqwzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (224, 224, 3)\n",
        "BATCH_SIZE = 10"
      ],
      "metadata": {
        "id": "415XkseARIOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(subset):\n",
        "  return tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      \"data/CSE164_2023/Train set\",\n",
        "      label_mode=\"categorical\",\n",
        "      color_mode=\"rgb\",\n",
        "      class_names= [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n",
        "      batch_size=1,\n",
        "      image_size=(224,224),\n",
        "      seed=seed,\n",
        "      validation_split=.2,\n",
        "      subset=subset,)\n",
        "\n",
        "train_ds = build_dataset(\"training\")\n",
        "class_names = tuple(train_ds.class_names)\n",
        "train_size = train_ds.cardinality().numpy()\n",
        "train_ds = train_ds.unbatch().batch(BATCH_SIZE)\n",
        "train_ds = train_ds.repeat()\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
        "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "  preprocessing_model.add(\n",
        "      tf.keras.layers.RandomRotation(40))\n",
        "  preprocessing_model.add(\n",
        "      tf.keras.layers.RandomTranslation(0, 0.2))\n",
        "  preprocessing_model.add(\n",
        "      tf.keras.layers.RandomTranslation(0.2, 0))\n",
        "  # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
        "  # image sizes are fixed when reading, and then a random zoom is applied.\n",
        "  # If all training inputs are larger than image_size, one could also use\n",
        "  # RandomCrop with a batch size of 1 and rebatch later.\n",
        "  preprocessing_model.add(\n",
        "      tf.keras.layers.RandomZoom(0.2, 0.2))\n",
        "  preprocessing_model.add(\n",
        "      tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
        "train_ds = train_ds.map(lambda images, labels:\n",
        "                        (preprocessing_model(images), labels))\n",
        "\n",
        "val_ds = build_dataset(\"validation\")\n",
        "valid_size = val_ds.cardinality().numpy()\n",
        "val_ds = val_ds.unbatch().batch(BATCH_SIZE)\n",
        "val_ds = val_ds.map(lambda images, labels:\n",
        "                    (normalization_layer(images), labels))"
      ],
      "metadata": {
        "id": "bauziFuVWY9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0630ea-79ec-4e77-b1d7-d9cc4c014d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 files belonging to 10 classes.\n",
            "Using 80 files for training.\n",
            "Found 100 files belonging to 10 classes.\n",
            "Using 20 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(40),\n",
        "    preprocessing.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0, 0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2, 0.2),\n",
        "], name=\"data_augmentation\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4tTWtBgEikzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training SWIN-T\n",
        "=================="
      ],
      "metadata": {
        "id": "OR4x7WfyXzIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "do_fine_tuning = False\n",
        "model = tf.keras.Sequential([\n",
        "    # Explicitly define the input shape so the model can be properly\n",
        "    # loaded by the TFLiteConverter\n",
        "    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "    data_augmentation,\n",
        "    hub.KerasLayer(\"https://tfhub.dev/sayakpaul/swin_base_patch4_window7_224/1\", trainable=do_fine_tuning),\n",
        "    tf.keras.layers.Dense(units=1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(len(class_names),\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2())\n",
        "])\n",
        "model.build((None,)+input_shape)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7-KhKQHX53v",
        "outputId": "ca6c8180-7aa7-4cf9-8c03-b0b946cbf806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
            " al)                                                             \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 1000)              87768224  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1025024   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88,803,498\n",
            "Trainable params: 1,035,274\n",
            "Non-trainable params: 87,768,224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QYP7mVrlYcZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"model\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "DSXrcmVFxvje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Model 3 times in order to take advantage of the model checkpoint, and so that it can continue to train without overfitting. It also takes all of the chance out of the model accuarcy"
      ],
      "metadata": {
        "id": "2jV0zN9dMdlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = valid_size // BATCH_SIZE\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[callback, model_checkpoint_callback]).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVjF0CDIYe3K",
        "outputId": "f3607983-c4b4-4f9e-bdeb-bc95da2bc606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 37s 1s/step - loss: 3.1314 - accuracy: 0.2000 - val_loss: 2.3883 - val_accuracy: 0.3000\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 4s 588ms/step - loss: 2.1806 - accuracy: 0.3750 - val_loss: 1.7844 - val_accuracy: 0.4500\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 5s 677ms/step - loss: 1.7280 - accuracy: 0.5625 - val_loss: 1.5309 - val_accuracy: 0.7000\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 5s 647ms/step - loss: 1.6686 - accuracy: 0.5750 - val_loss: 1.3716 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 1.5016 - accuracy: 0.6625 - val_loss: 1.4555 - val_accuracy: 0.6000\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 5s 685ms/step - loss: 1.3252 - accuracy: 0.6750 - val_loss: 1.1265 - val_accuracy: 0.8000\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 1.3463 - accuracy: 0.7250 - val_loss: 1.3739 - val_accuracy: 0.6500\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 4s 544ms/step - loss: 1.2024 - accuracy: 0.7500 - val_loss: 1.2573 - val_accuracy: 0.8500\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.0852 - accuracy: 0.8875 - val_loss: 1.0589 - val_accuracy: 0.9500\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 1.2089 - accuracy: 0.7625 - val_loss: 1.1311 - val_accuracy: 0.7000\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 1.1083 - accuracy: 0.8250 - val_loss: 1.0378 - val_accuracy: 0.8000\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 1.1372 - accuracy: 0.8250 - val_loss: 0.9866 - val_accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = valid_size // BATCH_SIZE\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[callback, model_checkpoint_callback]).history"
      ],
      "metadata": {
        "id": "B18pQJ4j54Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473f674b-7f81-450f-b66b-3cd1cfa47db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 1.0325 - accuracy: 0.8500 - val_loss: 1.0147 - val_accuracy: 0.9000\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 1.0027 - accuracy: 0.9125 - val_loss: 1.1056 - val_accuracy: 0.7000\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 1.1344 - accuracy: 0.8250 - val_loss: 1.1140 - val_accuracy: 0.8000\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 1.0839 - accuracy: 0.8500 - val_loss: 1.0836 - val_accuracy: 0.8000\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 0.9585 - accuracy: 0.9000 - val_loss: 1.1000 - val_accuracy: 0.8500\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 1.0482 - accuracy: 0.8250 - val_loss: 0.9769 - val_accuracy: 0.9000\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 2s 324ms/step - loss: 1.0925 - accuracy: 0.8125 - val_loss: 1.3333 - val_accuracy: 0.6000\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 1.0363 - accuracy: 0.8250 - val_loss: 0.9573 - val_accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_size // BATCH_SIZE\n",
        "validation_steps = valid_size // BATCH_SIZE\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[callback, model_checkpoint_callback]).history"
      ],
      "metadata": {
        "id": "0u9kYyzKIJ2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e734fb88-b327-44e9-90cb-1cfe148ea0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 0.9267 - accuracy: 0.8750 - val_loss: 1.2018 - val_accuracy: 0.6500\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 2s 304ms/step - loss: 0.9657 - accuracy: 0.8500 - val_loss: 0.9707 - val_accuracy: 0.8000\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.9222 - accuracy: 0.9000 - val_loss: 1.3751 - val_accuracy: 0.6500\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 1.0216 - accuracy: 0.8750 - val_loss: 1.1163 - val_accuracy: 0.8000\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.9414 - accuracy: 0.8750 - val_loss: 0.9527 - val_accuracy: 0.9500\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.9959 - accuracy: 0.9000 - val_loss: 1.1486 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model\", save_format='h5')"
      ],
      "metadata": {
        "id": "eb9OcoE-lYeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit Supervised Model\n",
        "=================="
      ],
      "metadata": {
        "id": "00lQ_wzaTaH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"data/CSE164_2023/Test set\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciO5sSuVL3kS",
        "outputId": "477df8d1-bd95-400d-d3e7-7c27478b9b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/CSE164_2023/Test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Specify the directory\n",
        "directory = ''\n",
        "\n",
        "# Specify the pattern\n",
        "pattern   = \"**/*.jpeg\"  # This will match any jpg file\n",
        "\n",
        "# Use glob to get all file paths\n",
        "image_paths = glob.glob(os.path.join(directory, pattern), recursive=True)\n",
        "# len(image_paths)\n",
        "# print(image_paths[:5])"
      ],
      "metadata": {
        "id": "V5pE_8MbL2vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next Cell takes like 6 minutes to run. That mainly has to do with memory constraints of having to do small batches of images"
      ],
      "metadata": {
        "id": "unPecdvcK-KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_array = []\n",
        "\n",
        "predictions = []\n",
        "# Define batch size\n",
        "batch_size = 10\n",
        "\n",
        "# Create list of path batches\n",
        "path_batches = [image_paths[i:i + batch_size] for i in range(0, len(image_paths), batch_size)]\n",
        "\n",
        "for path_batch in path_batches:\n",
        "    images_batch = []\n",
        "    for path in path_batch:\n",
        "        image_string = tf.io.read_file(path)\n",
        "        # Decode the image file\n",
        "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "\n",
        "        image_resized = tf.image.resize(image_decoded, [224, 224])\n",
        "        image_float = tf.image.convert_image_dtype(image_resized, tf.float32)\n",
        "        image_float = normalization_layer(image_float)\n",
        "        images_batch.append(image_float)\n",
        "\n",
        "    images_batch = np.array(images_batch)\n",
        "    predictions.extend(tf.argmax(model.predict(images_batch, verbose=0), axis=-1).numpy())\n",
        "\n",
        "# print(images_batch[0])\n",
        "# print(predictions[:10])"
      ],
      "metadata": {
        "id": "5ZQ0d7NrLTMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIoS-xrvL-PU",
        "outputId": "9cfd0175-81da-4f2d-e585-6afb8c15de73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/CSE164_2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hP2quq4MDnJ",
        "outputId": "c1cd0c45-0d2b-47d6-d2ec-43d85fef2bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDpN0n4kMFKx",
        "outputId": "e2391d7d-7ab1-462b-a573-113c234882f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suppose `predicted_labels` is a numpy array of your predicted labels\n",
        "# and `image_names` is a list or numpy array of your unlabeled image names\n",
        "\n",
        "\n",
        "# TODO\n",
        "# Check how they match up, because the images might be getting the wrong labels\n",
        "# Since the two arrays are not linked in any way\n",
        "\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Image_id': image_paths,\n",
        "    'label': predictions\n",
        "})\n",
        "\n",
        "# Export DataFrame to .csv file\n",
        "df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "wviGm2ddTxwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c ucsc-cse-164-spring-2023-final-project -f predictions.csv -m \"Message\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG39zrf2T3P0",
        "outputId": "a7a7b84c-09d6-49c1-a031-864b7b9b694c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0.00/116k [00:00<?, ?B/s]\r100% 116k/116k [00:00<00:00, 584kB/s]\n",
            "Successfully submitted to UCSC CSE 164 Spring 2023 Final Project"
          ]
        }
      ]
    }
  ]
}